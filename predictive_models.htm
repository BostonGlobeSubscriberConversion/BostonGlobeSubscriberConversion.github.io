
<!DOCTYPE html>
<html lang="en">
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<meta name="description" content="">
		<meta name="author" content="">

		<title>AC 297r Boston Globe Capstone Project Website</title>

		<!-- Bootstrap core CSS -->
		<link href="./bootstrap-3.3.1/css/bootstrap.min.css" rel="stylesheet">
		
		<!-- Bootstrap core CSS -->
		<link href="./bootstrap-3.3.1/css/bootstrap.icon-large.min.css" rel="stylesheet">
		
		<!-- Custom styles for the homepage -->
		<link href="./css/main.css" rel="stylesheet">

		<!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
		    <!--[if lt IE 9]>
		      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
		        <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
		        <![endif]-->
	</head>
	
<body>
<!-- Fixed navbar -->
<nav class="navbar navbar-default navbar-fixed-top">
  <div class="container-fluid">
    <div class="navbar-header">
		<button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-responsive-collapse">
			<span class="icon-bar"></span>
			<span class="icon-bar"></span>
			<span class="icon-bar"></span>
		  </button>
      <a class="navbar-brand" href="./index.htm">Boston Globe Subscriber Conversion</a>
    </div>
    <div class="navbar-collapse collapse navbar-responsive-collapse">
      <ul class="nav navbar-nav">
        <li><a href="./background.htm">BACKGROUND</a></li>
        <li><a href="./data.htm">DATA</a></li>
		<li class="dropdown">
			<a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">ANALYSIS <span class="caret"></span></a>
				<ul class="dropdown-menu" role="menu">
					<li><a href="./descriptive_analysis.htm">DESCRIPTIVE ANALYSIS</a></li>
					<li><a href="./predictive_models.htm">PREDICTIVE MODELS</a></li>
				</ul>
		</li>
        <li><a href="./next_steps.htm">NEXT STEPS</a></li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
		<li><a href="./about_us.htm">ABOUT THE AUTHORS</a></li> 
      </ul>
    </div>
  </div>
</nav>

<!-- Content -->
<!-- Collapsible Bar -->
<!-- Add Padding -->
  </br>
  </br>
  </br>
  </br>
<div class="container">
	<!-- Edit main content here. -->
	<h2>PREDICTIVE MODELS</h2>
	<h2>Interpretation Method</h2>
	<p>During the first phase of the project, we quickly realized that the subscription model is a supervised machine learning problem. Moreover, it is a binary classification problem where we are going to build a classifier to differentiate potential subscribers and non-subscribers. In the machine learning literature, there are many viable techniques such as logistic regression, decision trees, support vector machines and random forest to choose from.</p>
	<p>For the project, we decided to use random forest because the data includes many categorical data and, moreover, the underlying concept of decision tree is intuitive to explain to the client. We were also interested in using random forest’s feature importance statistics to perform variable selection. Our machine learning classifier is implemented with scikit-learn.</p>
	<p>We used the following for predictor variables.</p>
	<ul type="square">
	<li>Static features, which we use modes:</li>
		<ul type="circle">
		<li>geo_country, geo_region, geo_city, geo_zip;</li>
		<li>Derived.OS_Name, Derived.OS_Version, Derived.BrowerInUse_BrowserName, Derived.BrowserInUse_Version, Derived.DeviceIdentification</li>
		</ul>
	<li>Non-static features, which we use modes:</li>
		<ul type="circle">
		<li>daily_visitor_mode, post_channel_mode, post_cookies_mode, post_search_engine_mode, ref_domain_mode, domain_mode</li>
		</ul>
	<li>Non-static features, which we use maxima:</li>
		<ul type="circle">
		<li>visit_num_max, visit_page_num_max</li>
		</ul>
	<li>Non-static features, which we use distributions:</li>
		<ul type="circle">
		<li>post_channel distribution</li>
		</ul>
	</ul>
	<h2>Interpretation Result</h2>
	<p>In our final random forest classifier, we trained the classifier with the above 18 predicator variables. Performing a cross-validation using 60% of the training data and validating on 40% of the training data, the classifier was able to achieve an overall accuracy of 96%. We also see that both precision and recall are also in the 95-96% range. The classifier shows that the predictors we chose and feature engineered had significant predictive power.</p>
	<img src="img/predictive_analysis/interpretation result.png" alt="Non_sub_1" align="center" class="img-responsive" />
	<p>In addition, we also looked at the importance of our features in the random forest. The bar chart below shows that the most predictive covariate is the mode of a user’s daily visitor flag, followed by a few different content related covariates. Interestingly, geographic variables also show up with geo_zip and geo_city. Lastly, the type of browser is also predicative.</p>
	<img src="img/predictive_analysis/interpretation result2.png" alt="Non_sub_2" align="center" class="img-responsive" />
	<h2>Prediction Method</h2>
	<p>Next, we explored a new test set to validate our classifier. The idea is to simulate the practical situation of prediction. We trained our data on pre-2015 data and tested on 2015 data to see how many subscribers can we accurately predict to sign up. First, we defined a window of 7 days before the target date, January 1, 2015. During this window, we identified subscribers who were active during this period and also did not subscribe as of January 1, 2015. With these criteria, we find that there are approximately 1,800 future subscribers and 800 non-subscribers. We then take all of their observations out of the training data and retrained the classifier. Lastly, we ran the trained classifier and tested on the 2,600 potential subscribers.</p>
	<h2>Prediction Result</h2>
	<p>The result of the simulated prediction is shown below.</p>
	<img src="img/predictive_analysis/prediction result.png" alt="Non_sub_1" align="center" class="img-responsive" />
	<p>With this classifier, our accuracy and  recall decreased to 80% range. However, our precision stayed relatively high. We also show the confusion matrix below for a detailed breakdown of classification.</p>
	<table class="table table-bordered" align="center" style="width:60%; font-size:20px" border="1">
		<tr>
			<th></th>
			<th>Predicted Non-subscriber</th>
			<th>Predicted Subscriber</th>		
		</tr>
		<tr>
			<td>Non-subscriber</td>
			<td>645</td>		
			<td>125</td>
		</tr>
		<tr>
			<td>Subscriber</td>
			<td>338</td>		
			<td>1550</td>
		</tr>
	</table>
	<p>Lastly, we looked at the trade-off between precision and recall when we adjust the classifier’s threshold to classify subscribers. The default threshold is at 0.5 where if the probability is greater or equal to 0.5, the classifier would classify the observation as a subscriber. As we can see from the plot, as we increase the threshold, there is a sharp decrease in recall and small gain in precision.</p>
	<img src="img/predictive_analysis/prediction result2.png" alt="Non_sub_1" align="center" class="img-responsive" />
	<img src="img/predictive_analysis/prediction result3.png" alt="Non_sub_1" align="center" class="img-responsive" />
	<p>Lastly, we can calculate the improvement in subscriber detection rate. Before the implementation of this classifier, the naive rate can be calculated as 25,000 divided 80 million (unique visitors). This is around 1/3,200. This means that out of every 3,200 people who visit the site, 1 of them becomes a subscriber.</p>
	<p>With our statistical classifier which has a precision of 92% which means that on average, every 100 users that we predict to subscribe, 8 of them will be false positives and will not subscribe. If we assume that our false positive rate scaled up to the 80 million visitors. This will mean that our classifier will produce 6.4 million false positive. Since we have a recall percentage of 82%, we can identify 20,500 of the true subscribers. This means that our subscriber detection can be calculated as 20,500 divided by 6.4 million, which is 1/300. This means that on average, every 300 people we identify, 1 of them will subscribe. This is juxtaposed to the current system where we know that 1/3200 people subscribe. In conclusion, we improved the subscriber detection rate from 1/3200 to 1/300.</p>
	

</div>
	

<!-- Bootstrap core JavaScript. Placed at the end of the document so the pages load faster. -->
<script src="./js/jquery-1.11.1.min.js"></script>
<script src="./bootstrap-3.3.1/js/bootstrap.min.js"></script>

</body>
</html>
